{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCCUPATIONS_ATTRIBUTES = [\n",
    "    'IQ',\n",
    "    'NetWorth', \n",
    "    'PercentWomen',\n",
    "    'SubstanceAbuseRate',\n",
    "    'PercentUnemployed',\n",
    "    'Weight',\n",
    "    'YearlyIncome',\n",
    "    'NumberOfPeople',\n",
    "    'JobSatisfactionLevel',\n",
    "    'CriminalHistory',\n",
    "    'DivorceRate',\n",
    "    'Dishonesty'\n",
    "]\n",
    "\n",
    "POLITICALFIGS_ATTRIBUTES = [\n",
    "    \"IQ\",\n",
    "    \"NetWorth\",\n",
    "    \"YearsMarried\", \n",
    "    \"MileTime\",\n",
    "    \"HoursWorked\",\n",
    "    \"DollarsInherited\",\n",
    "    \"PercentLies\",\n",
    "    \"Height\",\n",
    "    \"NumberOfCountriesVisited\",\n",
    "    \"NumberOfChildren\",\n",
    "    \"HoursSlept\"\n",
    "]\n",
    "\n",
    "COUNTRIES_ATTRIBUTES = [\n",
    "    \"IQ\",\n",
    "    \"Corruption\",\n",
    "    \"Homicides\",\n",
    "    \"IncomeInequality\", \n",
    "    \"InfantMortality\",\n",
    "    \"Population\",\n",
    "    \"Weight\",\n",
    "    \"Attractiveness\",\n",
    "    \"LifeExpectancy\",\n",
    "    \"SubstanceAbuseRate\",\n",
    "    \"HoursWorked\"\n",
    "]\n",
    "\n",
    "SYNTHETICNAMES_ATTRIBUTES = [\n",
    "    \"IQ\",\n",
    "    \"NetWorth\",\n",
    "    \"Height\",\n",
    "    \"Weight\", \n",
    "    \"Age\",\n",
    "    \"DailyStepCount\",\n",
    "    \"Attractiveness\",\n",
    "    \"YearlyIncome\",\n",
    "    \"Deadlift\",\n",
    "    \"LifeExpectancy\",\n",
    "    \"HoursWorked\",\n",
    "    \"HoursSlept\",\n",
    "    \"AlcoholicDrinksPerWeek\",\n",
    "    \"MonthlySpending\"\n",
    "]\n",
    "\n",
    "def attributes_helper(entity):\n",
    "    if entity.lower() == 'occupations':\n",
    "        return OCCUPATIONS_ATTRIBUTES\n",
    "    elif entity.lower() == 'politicalfigures':\n",
    "        return POLITICALFIGS_ATTRIBUTES\n",
    "    elif entity.lower() == 'countries':\n",
    "        return COUNTRIES_ATTRIBUTES\n",
    "    elif entity.lower() == 'syntheticnames':\n",
    "        return SYNTHETICNAMES_ATTRIBUTES\n",
    "    else:\n",
    "        raise ValueError(f\"Entity: {entity} not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_probes(results_path, labels_col, model):\n",
    "    full_df = pd.read_csv(results_path)\n",
    "\n",
    "    na_indices = full_df[labels_col].isna()\n",
    "    full_df = full_df[~na_indices]\n",
    "    \n",
    "    test_df = full_df[full_df['is_train'] == 0]\n",
    "    train_df = full_df[full_df['is_train'] == 1]\n",
    "\n",
    "    test_labels = test_df[labels_col]\n",
    "    if len(test_labels) < 2:\n",
    "        print(test_labels)\n",
    "        return\n",
    "    \n",
    "    train_labels = train_df[labels_col]\n",
    "\n",
    "    test_results = []\n",
    "    train_results = []\n",
    "\n",
    "    for i in range(50):\n",
    "        curr_col = f'{model}/{i}'\n",
    "        if curr_col not in test_df.columns:\n",
    "            break\n",
    "        test_predictions = test_df[curr_col]\n",
    "        train_predictions = train_df[curr_col]\n",
    "\n",
    "        try:\n",
    "            test_results.append(pearsonr(test_labels, test_predictions)[0])\n",
    "            train_results.append(pearsonr(train_labels, train_predictions)[0])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('cannot get pearsonr')\n",
    "            if len(test_labels) < 2:\n",
    "                print(f'test_labels: {test_labels}')\n",
    "            if len(test_predictions) < 2:\n",
    "                print(f'test_predictions: {test_predictions}')\n",
    "            print('----')\n",
    "    \n",
    "    return test_results, train_results\n",
    "\n",
    "def regular_max(model, entity, jailbreak_type, experiment_type):\n",
    "    '''\n",
    "    Gets the maximum scores on all the datasets for a specified model, entity, jailbreak_type for a specified experiment.\n",
    "\n",
    "    Experiment type is either \"main\", \"specific\", or \"pairs\".\n",
    "\n",
    "    Model should always be the instruct version. For base to instruct, we infer the base version\n",
    "\n",
    "    Returns: dictionary with entity attributes and the max score\n",
    "    '''\n",
    "    attributes = attributes_helper(entity)\n",
    "\n",
    "    model_family, model_name = model.split('/')\n",
    "\n",
    "    maxes = {}\n",
    "\n",
    "    for i, attribute in enumerate(attributes):\n",
    "        if jailbreak_type != '':\n",
    "            filename = f'../data/{entity}/{entity}{attribute}/results/{entity}{attribute}_{model_name}_{jailbreak_type}_{experiment_type}.csv'\n",
    "            response_col = f'{model}_{jailbreak_type}Jailbreak_response_parsed'\n",
    "        else:\n",
    "            if 'gemma' in model and 'it' in model:\n",
    "                model = model.replace('-it', '')\n",
    "            if 'llama' in model.lower() and 'instruct' in model.lower():\n",
    "                model = 'meta-llama/Llama-3.1-8B'\n",
    "            if 'qwen' in model.lower() and 'instruct' in model.lower():\n",
    "                model = 'Qwen/Qwen2.5-7B'\n",
    "            if 'yi' in model.lower() and 'chat' in model.lower():\n",
    "                model = model.replace('-Chat', '')\n",
    "            model_family, model_name = model.split('/')\n",
    "            filename = f'../data/{entity}/{entity}{attribute}/results/{entity}{attribute}_{model_name}_{experiment_type}.csv'\n",
    "            \n",
    "            response_col = f'{model}_response_parsed'\n",
    "\n",
    "        try:\n",
    "            test, train = main_probes(filename, response_col, model=model)\n",
    "            test = np.array(test)\n",
    "            maxes[attribute] = np.nanmax(test) # Use nanmax to ignore nan values when finding max\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'{model} {entity} {attribute} {jailbreak_type} failed')\n",
    "            print('-' * 30)\n",
    "            continue\n",
    "        \n",
    "    return maxes\n",
    "\n",
    "def base_to_instruct(model, entity, jailbreak_type):\n",
    "    attributes = attributes_helper(entity)\n",
    "\n",
    "    model_family, model_name = model.split('/')\n",
    "\n",
    "    model_instruct = model\n",
    "\n",
    "    if 'gemma' in model.lower():\n",
    "        model_base = model.replace('-it', '')\n",
    "    elif 'qwen' in model.lower():\n",
    "        model_base = 'Qwen/Qwen2.5-7B'\n",
    "    elif 'llama' in model.lower():\n",
    "        model_base = 'meta-llama/Llama-3.1-8B'\n",
    "    elif 'yi' in model.lower():\n",
    "        model_base = model.replace('-Chat', '')\n",
    "        \n",
    "\n",
    "    maxes = {}\n",
    "\n",
    "    for attribute in attributes:\n",
    "        filename = f'../data/{entity}/{entity}{attribute}/results/{entity}{attribute}_{model_base.split(\"/\")[-1]}_base_to_instruct.csv'\n",
    "        if jailbreak_type != '':\n",
    "            response_col = f'{model}_{jailbreak_type}Jailbreak_response_parsed'\n",
    "        else:\n",
    "            response_col = f'{model_base}_response_parsed'\n",
    "        try:\n",
    "            main_df = pd.read_csv(f'../data/{entity}/{entity}{attribute}/{entity}{attribute}.csv')\n",
    "            predictions_df = pd.read_csv(filename)\n",
    "        except:\n",
    "            print(f'{filename} not found')\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            na_indices = main_df[response_col].isna()\n",
    "        except Exception as e:\n",
    "            print(f'Not found: {attribute}')\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "        main_df = main_df[~na_indices]\n",
    "        predictions_df = predictions_df[~na_indices]\n",
    "\n",
    "        test_indices = main_df['is_train'] == 0\n",
    "        train_indices = main_df['is_train'] == 1\n",
    "        \n",
    "        test_labels = main_df[test_indices][response_col]\n",
    "        train_labels = main_df[train_indices][response_col]\n",
    "\n",
    "        test_predictions = predictions_df[test_indices]\n",
    "\n",
    "\n",
    "        test_results = []\n",
    "\n",
    "        for i in range(len(test_predictions.columns) - 3):\n",
    "            curr_col = test_predictions.columns[i + 3]\n",
    "            try:\n",
    "                test_results.append(pearsonr(test_labels, test_predictions[curr_col])[0])\n",
    "            except ValueError as e:\n",
    "\n",
    "                break\n",
    "        try:\n",
    "            maxes[attribute] = np.array(test_results).max()\n",
    "        except Exception as e:\n",
    "            print(f'failed on {model} {entity} {jailbreak_type} {attribute}')\n",
    "            print(e)\n",
    "        \n",
    "    return maxes\n",
    "\n",
    "def bradley_terry(model, entity, jailbreak_type, experiment_type):\n",
    "    attributes = attributes_helper(entity)\n",
    "\n",
    "    model_family, model_name = model.split('/')\n",
    "\n",
    "    model_instruct = model\n",
    "\n",
    "    if 'gemma' in model.lower():\n",
    "        model_base = model.replace('-it', '')\n",
    "    elif 'qwen' in model.lower():\n",
    "        model_base = 'Qwen/Qwen2.5-7B'\n",
    "    elif 'llama' in model.lower():\n",
    "        model_base = 'meta-llama/Llama-3.1-8B'\n",
    "    elif 'yi' in model.lower():\n",
    "        model_base = model.replace('-Chat', '')\n",
    "        \n",
    "\n",
    "    maxes = {}\n",
    "\n",
    "    for attribute in attributes:\n",
    "        probes_predictions_filename = f'../data/{entity}/{entity}{attribute}/results/{entity}{attribute}_{model_name}_{jailbreak_type}_{experiment_type}.csv'\n",
    "        filename = f'../data/{entity}/{entity}{attribute}/{entity}{attribute}.csv'\n",
    "        full_df = pd.read_csv(filename)\n",
    "        if jailbreak_type != '':\n",
    "            response_col = f'{model}_{jailbreak_type}Jailbreak_bradley_terry_scores'\n",
    "        else:\n",
    "            raise NotImplementedError('Only jailbreaking for bradley terry')\n",
    "    \n",
    "        \n",
    "        bradley_terry_scores = full_df[response_col]\n",
    "        probes_predictions = pd.read_csv(probes_predictions_filename)\n",
    "\n",
    "        test_results = []\n",
    "\n",
    "        for i in range(len(probes_predictions.columns) - 3):\n",
    "            curr_col = probes_predictions.columns[i + 3]\n",
    "            try:\n",
    "                test_results.append(spearmanr(bradley_terry_scores, probes_predictions[curr_col])[0])\n",
    "            except ValueError as e:\n",
    "                break\n",
    "        try:\n",
    "            maxes[attribute] = np.nanmax(np.array(test_results))\n",
    "        except Exception as e:\n",
    "            print(f'failed on {model} {entity} {jailbreak_type} {attribute}')\n",
    "            print(e)\n",
    "        \n",
    "    return maxes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regular_results(entity, jailbreak_type, experiment_type, save=False):\n",
    "    if experiment_type.lower() in ('main', 'specific'):\n",
    "        gemma_result = regular_max('google/gemma-2-9b-it', entity, jailbreak_type, experiment_type)\n",
    "        gemma_small_result = regular_max('google/gemma-2-2b-it', entity, jailbreak_type, experiment_type)\n",
    "        yi_result = regular_max('01-ai/Yi-6B-Chat', entity, jailbreak_type, experiment_type)\n",
    "    elif experiment_type.lower() == 'base_to_instruct':\n",
    "        gemma_result = base_to_instruct('google/gemma-2-9b-it', entity, jailbreak_type)\n",
    "        gemma_small_result = base_to_instruct('google/gemma-2-2b-it', entity, jailbreak_type)\n",
    "        yi_result = base_to_instruct('01-ai/Yi-6B-Chat', entity, jailbreak_type)\n",
    "    elif experiment_type.lower() == 'bradley_terry':\n",
    "        gemma_result = bradley_terry('google/gemma-2-9b-it', entity, jailbreak_type, 'main')\n",
    "        gemma_small_result = bradley_terry('google/gemma-2-2b-it', entity, jailbreak_type, 'main')\n",
    "        yi_result = bradley_terry('01-ai/Yi-6B-Chat', entity, jailbreak_type, 'main')\n",
    "\n",
    "    if jailbreak_type != '':\n",
    "        df = pd.DataFrame({'gemma-2-9b-it': gemma_result, 'gemma-2-2b-it': gemma_small_result, 'Yi-6B-Chat': yi_result})\n",
    "    else:\n",
    "        df = pd.DataFrame({'gemma-2-9b': gemma_result, 'gemma-2-2b': gemma_small_result, 'Yi-6B': yi_result})\n",
    "    df = df.T\n",
    "\n",
    "    # Plotting\n",
    "    width = 0.25  # width of the bars\n",
    "    x = np.arange(len(df.columns))  # Use consistent x-axis based on columns\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    if jailbreak_type != '':\n",
    "        bars1 = ax.bar(x - width, df.loc['gemma-2-9b-it'], width, label='gemma-2-9b-it')\n",
    "        bars2 = ax.bar(x, df.loc['gemma-2-2b-it'], width, label='gemma-2-2b-it')\n",
    "        bars3 = ax.bar(x + width, df.loc['Yi-6B-Chat'], width, label='Yi-6B-Chat')\n",
    "    else:\n",
    "        bars1 = ax.bar(x - width, df.loc['gemma-2-9b'], width, label='gemma-2-9b')\n",
    "        bars2 = ax.bar(x, df.loc['gemma-2-2b'], width, label='gemma-2-2b-it')\n",
    "        bars3 = ax.bar(x + width, df.loc['Yi-6B'], width, label='Yi-6B')\n",
    "\n",
    "    for bar in bars1:\n",
    "        bar.set_facecolor('#86a873')  # Muted green\n",
    "    for bar in bars2:\n",
    "        bar.set_facecolor('#7c9fb0')  # Muted blue\n",
    "    for bar in bars3:\n",
    "        bar.set_facecolor('#c17767')  # Muted red\n",
    "\n",
    "    # Format entity name for title\n",
    "    display_entity = entity.replace('syntheticNames', 'Synthetic Names').replace('politicalFigures', 'Political Figures')\n",
    "    \n",
    "    # Format jailbreak type for title\n",
    "    display_jailbreak = ''\n",
    "    if jailbreak_type == 'icl':\n",
    "        display_jailbreak = 'ICL prompt'\n",
    "    elif jailbreak_type == 'machiavelli':\n",
    "        display_jailbreak = 'AIM prompt'\n",
    "    elif jailbreak_type != '':\n",
    "        display_jailbreak = jailbreak_type\n",
    "\n",
    "    # Labeling with larger font sizes\n",
    "    ax.set_ylabel('Pearson Correlation', fontsize=14)\n",
    "    if experiment_type.lower() in ('main', 'specific'):\n",
    "        ax.set_title(f'Linear Decodability of {display_entity} Attributes using {display_jailbreak}', fontsize=16)\n",
    "    elif experiment_type.lower() == 'base_to_instruct':\n",
    "        ax.set_title(f'BASE TO INSTRUCT\\nLinear Decodability of {display_entity} Attributes using {display_jailbreak}', fontsize=16)\n",
    "    elif experiment_type.lower() == 'bradley_terry':\n",
    "        ax.set_title(f'PAIRWISE COMPARISONS\\nLinear Decodability of {display_entity} Attributes using {display_jailbreak}', fontsize=16)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df.columns, rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        os.makedirs('plots', exist_ok=True)\n",
    "        os.makedirs(f'plots/{experiment_type}', exist_ok=True)\n",
    "        plt.savefig(f'plots/{experiment_type}/{entity}_{jailbreak_type}_{experiment_type}.pdf', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_difference_results(entity, jailbreak_type, save=False):\n",
    "    # Get results for 'specific' and 'main'\n",
    "    gemma_specific = regular_max('google/gemma-2-9b-it', entity, jailbreak_type, 'specific')\n",
    "    gemma_small_specific = regular_max('google/gemma-2-2b-it', entity, jailbreak_type, 'specific')\n",
    "    yi_specific = regular_max('01-ai/Yi-6B-Chat', entity, jailbreak_type, 'specific')\n",
    "\n",
    "    gemma_main = regular_max('google/gemma-2-9b-it', entity, jailbreak_type, 'main')\n",
    "    gemma_small_main = regular_max('google/gemma-2-2b-it', entity, jailbreak_type, 'main')\n",
    "    yi_main = regular_max('01-ai/Yi-6B-Chat', entity, jailbreak_type, 'main')\n",
    "\n",
    "    # Calculate differences\n",
    "    gemma_diff = {k: gemma_specific[k] - gemma_main[k] for k in gemma_specific}\n",
    "    gemma_small_diff = {k: gemma_small_specific[k] - gemma_small_main[k] for k in gemma_small_specific}\n",
    "    yi_diff = {k: yi_specific[k] - yi_main[k] for k in yi_specific}\n",
    "\n",
    "    # Create DataFrame for differences\n",
    "    if jailbreak_type != '':\n",
    "        df_diff = pd.DataFrame({'gemma-2-9b-it': gemma_diff, 'gemma-2-2b-it': gemma_small_diff, 'Yi-6B-Chat': yi_diff})\n",
    "    else:\n",
    "        df_diff = pd.DataFrame({'gemma-2-9b': gemma_diff, 'gemma-2-2b': gemma_small_diff, 'Yi-6B': yi_diff})\n",
    "    df_diff = df_diff.T\n",
    "\n",
    "    # Plotting differences\n",
    "    width = 0.25\n",
    "    x = np.arange(len(df_diff.columns))  # Use consistent x-axis based on columns\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    if jailbreak_type != '':\n",
    "        bars1 = ax.bar(x - width, df_diff.loc['gemma-2-9b-it'], width, label='gemma-2-9b-it')\n",
    "        bars2 = ax.bar(x, df_diff.loc['gemma-2-2b-it'], width, label='gemma-2-2b-it')\n",
    "        bars3 = ax.bar(x + width, df_diff.loc['Yi-6B-Chat'], width, label='Yi-6B-Chat')\n",
    "    else:\n",
    "        bars1 = ax.bar(x - width, df_diff.loc['gemma-2-9b'], width, label='gemma-2-9b')\n",
    "        bars2 = ax.bar(x, df_diff.loc['gemma-2-2b'], width, label='gemma-2-2b')\n",
    "        bars3 = ax.bar(x + width, df_diff.loc['Yi-6B'], width, label='Yi-6B')\n",
    "\n",
    "    for bar in bars1:\n",
    "        bar.set_facecolor('#86a873')  # Muted green\n",
    "    for bar in bars2:\n",
    "        bar.set_facecolor('#7c9fb0')  # Muted blue\n",
    "    for bar in bars3:\n",
    "        bar.set_facecolor('#c17767')  # Muted red\n",
    "\n",
    "    # Format entity name for title\n",
    "    display_entity = entity.replace('syntheticNames', 'Synthetic Names').replace('politicalFigures', 'Political Figures')\n",
    "    \n",
    "    # Format jailbreak type for title\n",
    "    display_jailbreak = ''\n",
    "    if jailbreak_type == 'icl':\n",
    "        display_jailbreak = 'ICL prompt'\n",
    "    elif jailbreak_type == 'machiavelli':\n",
    "        display_jailbreak = 'AIM prompt'\n",
    "    elif jailbreak_type != '':\n",
    "        display_jailbreak = jailbreak_type\n",
    "\n",
    "    # Labeling with larger font sizes\n",
    "    ax.set_ylabel('Difference in Pearson Correlation', fontsize=14)\n",
    "    ax.set_title(f'Difference in Linear Decodability of {display_entity} Attributes using {display_jailbreak}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_diff.columns, rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_yticks(np.arange(-0.3, 1.1, 0.1))\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        os.makedirs('plots', exist_ok=True)\n",
    "        os.makedirs('plots/difference', exist_ok=True)\n",
    "        plt.savefig(f'plots/difference/{entity}_{jailbreak_type}_difference.pdf', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_plots_all_attributes(entity, jailbreak_type, save=False):\n",
    "    entity_attr_map = {\n",
    "        'Occupations': OCCUPATIONS_ATTRIBUTES,\n",
    "        'Countries': COUNTRIES_ATTRIBUTES,\n",
    "        'politicalFigures': POLITICALFIGS_ATTRIBUTES\n",
    "    }\n",
    "\n",
    "    entity_title_map = {\n",
    "        'Occupations': 'Occupations',\n",
    "        'Countries': 'Countries',\n",
    "        'politicalFigures': 'Political Figures'\n",
    "    }\n",
    "\n",
    "    model_list = [\n",
    "        'google/gemma-2-9b-it',\n",
    "        'google/gemma-2-2b-it',\n",
    "        '01-ai/Yi-6B-Chat'\n",
    "    ]\n",
    "\n",
    "    model_colors = {\n",
    "        'google/gemma-2-9b-it': '#88a45b',\n",
    "        'google/gemma-2-2b-it': '#5694b9',\n",
    "        '01-ai/Yi-6B-Chat': '#c17767'\n",
    "    }\n",
    "\n",
    "    attributes = entity_attr_map.get(entity)\n",
    "    if attributes is None:\n",
    "        print(f\"Unknown entity: {entity}\")\n",
    "        return\n",
    "\n",
    "    num_attrs = len(attributes)\n",
    "    ncols = 2\n",
    "    nrows = (num_attrs + 1) // ncols\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows), sharey='row')\n",
    "    fig.suptitle(entity_title_map[entity], fontsize=24, y=0.98)\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Global legend handles\n",
    "    model_handles = [\n",
    "        plt.Line2D([], [], marker='o', linestyle='', color=model_colors[m], label=m.split('/')[-1])\n",
    "        for m in model_list\n",
    "    ]\n",
    "\n",
    "    for i, attribute in enumerate(attributes):\n",
    "        ax = axs[i]\n",
    "        per_model_spearman = []\n",
    "\n",
    "        for model in model_list:\n",
    "            try:\n",
    "                short_model = model.split(\"/\")[-1]\n",
    "                full_df = pd.read_csv(f'../data/{entity}/{entity}{attribute}/{entity}{attribute}.csv')\n",
    "                brad_terry_col = f'{model}_{jailbreak_type}Jailbreak_bradley_terry_scores'\n",
    "                bradley_terry_scores = full_df[brad_terry_col]\n",
    "\n",
    "                probes_path = f'../data/{entity}/{entity}{attribute}/results/{entity}{attribute}_{short_model}_{jailbreak_type}_main.csv'\n",
    "                probes_predictions = pd.read_csv(probes_path)\n",
    "                probes_predictions = probes_predictions.iloc[:, 3:]\n",
    "\n",
    "                scores = [\n",
    "                    spearmanr(bradley_terry_scores, probes_predictions[col])[0]\n",
    "                    for col in probes_predictions.columns\n",
    "                ]\n",
    "\n",
    "                best_layer = np.nanargmax(scores)\n",
    "                best_layer_score = scores[best_layer]\n",
    "                best_layer_name = probes_predictions.columns[best_layer]\n",
    "\n",
    "                color = model_colors[model]\n",
    "                ax.scatter(probes_predictions[best_layer_name], bradley_terry_scores,\n",
    "                           color=color, alpha=0.6, label=f'Spearman r = {best_layer_score:.3f}')\n",
    "\n",
    "                per_model_spearman.append((color, best_layer_score))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error for {model} on {attribute}: {e}\")\n",
    "                continue\n",
    "\n",
    "        ax.set_ylim(-20, 20)\n",
    "        ax.set_title(f'{attribute}', fontsize=16)\n",
    "        ax.set_xlabel('Probe Prediction', fontsize=12)\n",
    "        if i % ncols == 0:\n",
    "            ax.set_ylabel('Bradley-Terry Score', fontsize=12)\n",
    "        ax.tick_params(labelsize=10)\n",
    "        ax.legend(fontsize=10)\n",
    "\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    # Global legend\n",
    "    fig.legend(\n",
    "        handles=model_handles,\n",
    "        loc='lower center',\n",
    "        ncol=len(model_handles),\n",
    "        fontsize=11,\n",
    "        bbox_to_anchor=(0.5, -0.01)\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        os.makedirs('plots/bradley_terry', exist_ok=True)\n",
    "        filename = f'plots/bradley_terry/{entity}_{jailbreak_type}_bradley_terry.pdf'\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        print(f\"Saved plot to {filename}\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_corrs(model, jailbreak_type, entity='all', save=False):\n",
    "    if entity == 'all':\n",
    "        entity_list = ['Countries', 'Occupations', 'politicalFigures', 'syntheticNames']\n",
    "    else:\n",
    "        entity_list = [entity]\n",
    "\n",
    "    if jailbreak_type == 'all':\n",
    "        jailbreak_list = ['machiavelli', 'icl']\n",
    "    else:\n",
    "        jailbreak_list = [jailbreak_type]\n",
    "\n",
    "    # Colors per entity\n",
    "    entity_colors = {\n",
    "        'Countries': 'red',\n",
    "        'Occupations': 'blue',\n",
    "        'politicalFigures': 'green',\n",
    "        'syntheticNames': 'purple'\n",
    "    }\n",
    "\n",
    "    # Markers per jailbreak type\n",
    "    jailbreak_markers = {\n",
    "        'machiavelli': 'o',  # circle\n",
    "        'icl': 'x'           # cross\n",
    "    }\n",
    "\n",
    "    # Mapping for display labels in the legend\n",
    "    jailbreak_display_names = {\n",
    "        'machiavelli': 'AIM',\n",
    "        'icl': 'ICL'\n",
    "    }\n",
    "\n",
    "    # Results to compare\n",
    "    results_y_options = ['specific', 'base_to_instruct', 'bradley_terry']\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 9), sharex=False, sharey=False)\n",
    "    fig.suptitle(f\"{model} Result Correlations\", fontsize=18)\n",
    "\n",
    "    for ax, results_y in zip(axs, results_y_options):\n",
    "        all_results_x = []\n",
    "        all_results_y = []\n",
    "\n",
    "        for ent in entity_list:\n",
    "            for jb_type in jailbreak_list:\n",
    "                # x is always 'main'\n",
    "                x_scores = regular_max(model, ent, jb_type, 'main')\n",
    "\n",
    "                # y varies\n",
    "                if results_y == 'bradley_terry':\n",
    "                    y_scores = bradley_terry(model, ent, jb_type, 'main')\n",
    "                elif results_y == 'base_to_instruct':\n",
    "                    y_scores = base_to_instruct(model, ent, jb_type)\n",
    "                elif results_y == 'specific':\n",
    "                    y_scores = regular_max(model, ent, jb_type, 'specific')\n",
    "                else:\n",
    "                    raise ValueError(f'Unknown results_y: {results_y}')\n",
    "\n",
    "                # Keep only keys with valid values\n",
    "                common_keys = {k for k in (set(x_scores) & set(y_scores))\n",
    "                               if not (pd.isna(x_scores[k]) or pd.isna(y_scores[k]))}\n",
    "\n",
    "                x_vals = [x_scores[k] for k in common_keys]\n",
    "                y_vals = [y_scores[k] for k in common_keys]\n",
    "                color = entity_colors[ent]\n",
    "                marker = jailbreak_markers[jb_type]\n",
    "                display_jb_type = jailbreak_display_names[jb_type]\n",
    "\n",
    "                all_results_x.extend(x_vals)\n",
    "                all_results_y.extend(y_vals)\n",
    "\n",
    "                ax.scatter(x_vals, y_vals, color=color, marker=marker,\n",
    "                           label=f'{ent} ({display_jb_type})', alpha=0.7)\n",
    "\n",
    "        # Axes labeling and correlation\n",
    "        ax.set_title(f'main vs. {results_y}', fontsize=16)\n",
    "        ax.set_xlabel('main results', fontsize=16)\n",
    "        ax.set_ylabel(f'{results_y} results', fontsize=16)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        corr = spearmanr(all_results_x, all_results_y)[0]\n",
    "        ax.text(\n",
    "            0.02, 0.98, f'Spearman r = {corr:.3f}',\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=11,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray')\n",
    "        )\n",
    "\n",
    "    # Add single combined legend\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=4, fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.98])  # reserve space for bottom legend + top title\n",
    "    if save:\n",
    "        os.makedirs('plots/results_corrs', exist_ok=True)\n",
    "        filename = f'plots/results_corrs/{model.split(\"/\")[-1]}_{jailbreak_type}_results_corrs.pdf'\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        print(f\"Saved plot to {filename}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
